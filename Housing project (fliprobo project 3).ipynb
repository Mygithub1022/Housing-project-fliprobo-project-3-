{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries necessary fot this project\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "#Import supplementary visualizations code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "#pretty displays for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "#load the boston housing dataset\n",
    "data = pd.read_csv('housing.csv')\n",
    "prices = data['MEDV']\n",
    "features = data.drop('MEDV', axis = 1)\n",
    "\n",
    "#Success\n",
    "print(\"Boston housing dataset has {} data points with {} variables each.\"\n",
    "     .format(*data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration\n",
    "\n",
    "In the first section of the project, we will make an exploratory analysis of the dataset and\n",
    "some observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimum price of the data\n",
    "minimum_price = np.amin(prices)\n",
    "\n",
    "#Maximum price of the data\n",
    "maximum_price = np.amax(prices)\n",
    "\n",
    "#Mean price of the data\n",
    "mean_price = np.mean(prices)\n",
    "\n",
    "#Median price of the data\n",
    "median_price = np.median(prices)\n",
    "\n",
    "#standard deviations of prices of the data\n",
    "std_price = np.std(prices)\n",
    "\n",
    "#show the calculated statistics\n",
    "print(\"Statistics of housing dataset:\\n\")\n",
    "print(\"Minimum price: ${}\".format(minimum_price))\n",
    "print(\"Maximum price: ${}\".format(maximum_price))\n",
    "print(\"Mean price: ${}\".format(mean_price))\n",
    "print(\"Median price: ${}\".format(median_price))\n",
    "print(\"standard deviation of prices: ${}\".format(std_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Obseravation\n",
    "\n",
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#calculate and show pairplot\n",
    "sns.pairplot(data, size=2.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and show correlation matrix\n",
    "cm = np.corrcoef(data.values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "hm = sns.heatmap(cm,\n",
    "                cbar=True,\n",
    "                annot=True,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                annot_kws={'size': 15},\n",
    "                yticklables=cols,\n",
    "                xticklabels=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 'r2_score'\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    #Return the score\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 'train_test_split'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#shuffle and split data into training and testing subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features,\n",
    "                                                   prices,test_size=0.2, random_state 42)\n",
    "\n",
    "#success\n",
    "print(\"Training and testing split was successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produce learning curves for varying training set sizes and maximum depths\n",
    "vs.modelComplexity(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Models performance\n",
    "\n",
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [ {‘C’: [1, 10, 100, 1000], ‘kernel’: [‘linear’]}, {‘C’: [1, 10, 100, 1000], ‘gamma’: [0.001, 0.0001], \n",
    "                                                                 ‘kernel’: [‘rbf’]}, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation\n",
    "\n",
    "Fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth':[1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    grid = GridSearchCV(estimator=regressor, param_grid=params, scoring=scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions\n",
    "\n",
    "Optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the training data to the model using grid search\n",
    "reg = fit_model(x_train, y_train)\n",
    "\n",
    "#produce the value for 'max_depth'\n",
    "print(\"parameter 'max_depth' is {} for the optimal\n",
    "      model.\".format(reg.get_params() ['max_depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting selling prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a matrix for client data\n",
    "client_data = [[5, 17, 15], # Client 1\n",
    "               [4, 32, 22], # Client 2\n",
    "               [8, 3, 12]]  # Client 3\n",
    "\n",
    "# Show predictions\n",
    "for i, price in enumerate(reg.predict(client_data)):\n",
    "    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.predictTrails(features, prices, fit_model, client_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
